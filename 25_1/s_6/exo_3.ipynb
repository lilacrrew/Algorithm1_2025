{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Erniyaz Ashuov - Number 6 - first group**"
      ],
      "metadata": {
        "id": "0dh3iJgN0H8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0j5-WujR0IkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 1 (Fibonacci Super Fast!)**"
      ],
      "metadata": {
        "id": "86LmeCGbwi29"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaP0rqYCv7oz",
        "outputId": "9bb890f3-dfc8-4f30-f991-0cb1be81c5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "8\n",
            "55\n"
          ]
        }
      ],
      "source": [
        "def matrix_multiply(A, B):\n",
        "    result = [[0, 0], [0, 0]]\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            for k in range(2):\n",
        "                result[i][j] += A[i][k] * B[k][j]\n",
        "    return result\n",
        "\n",
        "def matrix_power(matrix, n):\n",
        "    result = [[1, 0], [0, 1]]\n",
        "    while n > 0:\n",
        "        if n % 2 == 1:\n",
        "            result = matrix_multiply(result, matrix)\n",
        "        matrix = matrix_multiply(matrix, matrix)\n",
        "        n //= 2\n",
        "    return result\n",
        "\n",
        "def fibonacci(n):\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    matrix = [[1, 1], [1, 0]]\n",
        "    result_matrix = matrix_power(matrix, n-1)\n",
        "    return result_matrix[0][0]\n",
        "\n",
        "print(fibonacci(0))\n",
        "print(fibonacci(1))\n",
        "print(fibonacci(2))\n",
        "print(fibonacci(3))\n",
        "print(fibonacci(4))\n",
        "print(fibonacci(5))\n",
        "print(fibonacci(6))\n",
        "print(fibonacci(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Master Theorem helps us figure out how long a problem will take to solve when we break it into smaller parts.\n",
        "\n",
        "For matrix exponentiation like Fibonacci the problem gets divided in half every time. So if we start with n, the next step is n/2, then n/4, and so on.\n",
        "\n",
        "This means the number of steps needed to finish is like counting how many times you can divide n by 2 before you get to 1. This is called log2 n.\n",
        "\n",
        "So, the time it takes to solve is O(log2 n). It gets smaller and smaller with each step, and thats why it’s logarithmic"
      ],
      "metadata": {
        "id": "eciavdGzwiHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4NFrBCs-xg9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2 (0/1 Knapsack Algorithm!)**"
      ],
      "metadata": {
        "id": "BnFbLhSnxhnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knapsack(weights, values, W):\n",
        "    n = len(weights)\n",
        "    dp = [0] * (W + 1)\n",
        "\n",
        "    for i in range(n):\n",
        "        for w in range(W, weights[i] - 1, -1):\n",
        "            dp[w] = max(dp[w], values[i] + dp[w - weights[i]])\n",
        "\n",
        "    return dp[W]\n",
        "\n",
        "weights1 = [1, 2, 3]\n",
        "values1 = [10, 20, 30]\n",
        "W1 = 5\n",
        "print(\"case 1 max value = \", knapsack(weights1, values1, W1))\n",
        "\n",
        "weights2 = [2, 3, 4, 5]\n",
        "values2 = [3, 4, 5, 6]\n",
        "W2 = 5\n",
        "print(\"case 2 max value = \", knapsack(weights2, values2, W2))\n",
        "\n",
        "weights3 = [1, 2, 3, 8, 7, 4]\n",
        "values3 = [20, 5, 10, 40, 15, 25]\n",
        "W3 = 10\n",
        "print(\"case 3 max value = \", knapsack(weights3, values3, W3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukuiKOS7xizG",
        "outputId": "62303797-5bb9-44c2-8606-9790a010dca6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "case 1 max value =  50\n",
            "case 2 max value =  7\n",
            "case 3 max value =  60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Why is Knapsack not greedy, and why dynamic programming?\n",
        "\n",
        "Knapsack is not greedy because a greedy algorithm only picks the best option at each step, without thinking about the future. But in Knapsack, we need to think about all items together to get the best result. Dynamic programming helps by remembering the best choices and finding the overall best solution.\n",
        "\n",
        "2. Solve the Knapsack Algorithm for the course example.\n",
        "\n",
        "We use dynamic programming to build a table that keeps track of the best value for each possible weight. We decide for each item if we should take it or leave it, and then find the highest value we can get.\n",
        "For items with weights [2, 3, 4] and values [3, 4, 5], if the weight limit is 5, the table tells us the best value is 7 by picking items with weight 2 and 3\n",
        "\n",
        "3. Can you get space complexity to O(W)?\n",
        "\n",
        "Yes, we can use a 1D array instead of a 2D table to save space. This makes the space complexity O(W) instead of O(n * W)."
      ],
      "metadata": {
        "id": "4RhlRI7ZyIwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "uo1kBF9jyXIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 3 (Neuro Computing!). 1. Generate 100 random binary vectors of length N, like**\n",
        "[1, 0, 0, 1, · · · , 0, 1]"
      ],
      "metadata": {
        "id": "VmPiZUdxyYOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_vectors(n, length):\n",
        "    return [[random.choice([0, 1]) for _ in range(length)] for _ in range(n)]\n",
        "\n",
        "def cosine_sim(x, y):\n",
        "    dot = sum(xi * yi for xi, yi in zip(x, y))\n",
        "    norm_x = sum(x)\n",
        "    norm_y = sum(y)\n",
        "    return dot / (norm_x * norm_y) if norm_x and norm_y else 0\n",
        "\n",
        "def jaccard_sim(x, y):\n",
        "    intersection = sum(xi * yi for xi, yi in zip(x, y))\n",
        "    union = sum(max(xi, yi) for xi, yi in zip(x, y))\n",
        "    return intersection / union if union else 0\n",
        "\n",
        "n = 100\n",
        "length = 10\n",
        "vectors = generate_vectors(n, length)\n",
        "\n",
        "x = vectors[0]\n",
        "y = vectors[1]\n",
        "\n",
        "cos_sim = cosine_sim(x, y)\n",
        "jaccard_sim = jaccard_sim(x, y)\n",
        "\n",
        "print(\"cosine sim:\", cos_sim)\n",
        "print(\"jaccard sim:\", jaccard_sim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5m2Xb_4zFWP",
        "outputId": "bae5c36a-e22b-4337-da5d-8dcd55f0fac7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cosine sim: 0.16666666666666666\n",
            "jaccard sim: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What happens when repeating the experience for larger Ns? Why?\n",
        "\n",
        "When N gets bigger the similarities between vectors change more because there are more bits so its more random. It looks like a gaussian curve\n",
        "\n",
        "4. Consider a huge sparse binary vector of length N = 2000 with w = 5, the number of random ones. How many possible such vectors are possible?\n",
        "You can choose 5 places for ones in a 2000 bit vector. The number of ways to do this is huge, and it's found by combinations\n",
        "(2000 5) = 2000!/5! * (2000-5)!​\n",
        "\n",
        "5. Can you think about a notion of capacity for these vectors?\n",
        "capacity is how many ones are in the vector. For sparse vectors the capacity is just how many ones are placed in the vector which is very small compared to the total length\n"
      ],
      "metadata": {
        "id": "-5UdX33OzSgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nZ-39DEG0BXc"
      }
    }
  ]
}